{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6549829d",
   "metadata": {},
   "source": [
    "The objective of this project is to analyze whether **daily news sentiment**, derived from Nvidia-related headlines, has any noticeable effect on the company’s **stock price**. By combining structured text data (news) with structured financial data (stock prices), we aim to uncover correlations that might hint at a relationship between what’s in the headlines and what’s happening in the markets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6777f4",
   "metadata": {},
   "source": [
    "For this project, we will use two primary datasets:\n",
    "\n",
    "* **Stock Prices from Yahoo Finance** — Using the `yfinance` library, we will obtain daily **closing prices** for Nvidia within our time range.\n",
    "* **News Headlines from NewsAPI** — We will use the keyword “Nvidia” to extract English-language headlines related to Nvidia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2025-01-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')  # This will give us the present date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = yf.Ticker('NVDA').history(start=start_date, end=end_date)\n",
    "stock_data.reset_index(inplace=True)\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://newsapi.org/v2/everything'\n",
    "params = {\n",
    "    'q': 'Nvidia', # We will use the keyword “Nvidia” to extract headlines related to Nvidia\n",
    "    'from': (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d'), # We will fetch news headlines in the past month\n",
    "    'sortBy': 'relevancy',\n",
    "    'apiKey': api_key,\n",
    "    'pageSize': 100,\n",
    "    'language': 'en' # We will extract English-language headlines\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params) # Sending a request and getting a response\n",
    "data = response.json()\n",
    "\n",
    "if data['status'] != 'ok':\n",
    "  raise Exception(f\"NewsAPI Error: {data['message']}\")\n",
    "\n",
    "articles = data['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.DataFrame(articles)\n",
    "news_data = news_data[['publishedAt', 'title']]\n",
    "news_data.columns = ['date', 'headline']\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec140052",
   "metadata": {},
   "source": [
    "To ensure the text data was useful for sentiment analysis, we performed the following cleaning steps:\n",
    "\n",
    "* **Only Alphabets in the Headlines** — Numbers, punctuation, and special characters will not contribute much in sentiment analysis.\n",
    "* **Removal of Stop Words from the Headlines** — Stopwords are the common words like \"the\", \"is\", \"and\" and many more, that add little meaning. Therefore, we have to erase these words from our headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab') # This downloads a pretrained tokenizer that helps split text into sentences or words\n",
    "nltk.download('stopwords') # This downloads the list of stopwords in various languages.\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "  words = word_tokenize(text)\n",
    "  words = [word for word in words if word.isalpha()] # Filtering out the non-alphabet characters\n",
    "  words = [word for word in words if word.lower() not in stop_words] # Filtering out the stop words\n",
    "  return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96182ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing news headlines\n",
    "news_data['cleaned_headline'] = news_data['headline'].apply(preprocess_text)\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d21cf8",
   "metadata": {},
   "source": [
    "Now, we have a column that displays every headline’s sentiment score. There are three kinds of sentiment scores:\n",
    "\n",
    "* $\\text{sentiment score} \\gt 0$ meaning the headline is in the favour of Nvidia.\n",
    "* $\\text{sentiment score} = 0$ meaning the headline is purely neutral.\n",
    "* $\\text{sentiment score} \\lt 0$ meaning the headline is not in the favour of Nvidia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade55e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "  score = analyzer.polarity_scores(text) # Every headline will be given a sentiment score.\n",
    "  return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ed672",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['sentiment_score'] = news_data['cleaned_headline'].apply(get_sentiment_score)\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures both dates are in the same format (datetime.date) because we are going to merge these dataframes.\n",
    "news_data['date'] = pd.to_datetime(news_data['date']).dt.date\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d900736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headlines are typically numerous per day, so we will aggregate them into a single daily sentiment score using summation\n",
    "aggregated_sentiment = news_data.groupby('date')['sentiment_score'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ea00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we we will combine our two dataframes and get one final dataframe.\n",
    "combined_data = pd.merge(stock_data, aggregated_sentiment, left_on='Date', right_on='date', how='inner')\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd578e9d",
   "metadata": {},
   "source": [
    "To analyze the relationship between sentiment and stock performance, we will use a dual-axis plot:\n",
    "\n",
    "* **Nvidia Stock Price** – shown as a blue line chart.\n",
    "* **Aggregated Sentiment Score** – shown as green/red bars (positive and negative scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d36dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Nvidia Stock Price')\n",
    "ax1.plot(combined_data['Date'], combined_data['Close'], label='Nvidia Stock Price')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Sentiment Score')\n",
    "\n",
    "colors = ['green' if val >= 0 else 'red' for val in combined_data['sentiment_score']]\n",
    "ax2.bar(combined_data['Date'], combined_data['sentiment_score'], label='Aggregated Sentiment Score', color=colors, alpha=0.6)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Nvidia Stock Price vs Aggregated Sentiment Score')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef4c12",
   "metadata": {},
   "source": [
    "This project showed that combining textual data with numerical financial data can uncover valuable signals in market behavior. While sentiment scores alone can’t predict prices, they can enhance our understanding of investor psychology and provide early warnings of shifts in perception."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
